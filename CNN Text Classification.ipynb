{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "import re\n",
    "from copy import deepcopy\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "torch.cuda.set_device(gpus[0])\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_batch(batch):\n",
    "    x,y = zip(*batch)\n",
    "    max_x = max([s.size(1) for s in x])\n",
    "    x_p = []\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1) < max_x:\n",
    "            x_p.append(torch.cat([x[i], Variable(LongTensor([word2index['<PAD>']] * (max_x - x[i].size(1)))).view(1, -1)], 1))\n",
    "        else:\n",
    "            x_p.append(x[i])\n",
    "    return torch.cat(x_p), torch.cat(y).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/INSPIREpy2.df')\n",
    "\n",
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "training_samples = 3 * len(data) // 5\n",
    "validation_samples = len(data) // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data['texts'])\n",
    "y = list(data['coreness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(X):\n",
    "    X[i] = re.sub('\\d', '#', x).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314551\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(flatten(X)))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(set(y))) # Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index={'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "target2index = {}\n",
    "\n",
    "for cl in set(y):\n",
    "    if target2index.get(cl) is None:\n",
    "        target2index[cl] = len(target2index)\n",
    "\n",
    "index2target = {v:k for k, v in target2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p, y_p = [], []\n",
    "for pair in zip(X,y):\n",
    "    X_p.append(prepare_sequence(pair[0], word2index).view(1, -1))\n",
    "    y_p.append(Variable(LongTensor([target2index[pair[1]]])).view(1, -1))\n",
    "    \n",
    "data_p = list(zip(X_p, y_p))\n",
    "random.shuffle(data_p)\n",
    "\n",
    "train_data = data_p[: int(len(data_p) * 0.6)]\n",
    "val_data = data_p[int(len(data_p) * 0.6):int(len(data_p) * 0.8)]\n",
    "test_data = data_p[int(len(data_p) * 0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/word2vec_pretrained/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = []\n",
    "\n",
    "for key in word2index.keys():\n",
    "    try:\n",
    "        pretrained.append(model[word2index[key]])\n",
    "    except:\n",
    "        pretrained.append(np.random.randn(300))\n",
    "        \n",
    "pretrained_vectors = np.vstack(pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, output_size, kernel_dim=100, kernel_sizes=(3, 4, 5), dropout=0.5):\n",
    "        super(CNNClassifier,self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, kernel_dim, (K, embedding_dim)) for K in kernel_sizes])\n",
    "\n",
    "        # kernal_size = (K,D) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * kernel_dim, output_size)\n",
    "    \n",
    "    \n",
    "    def init_weights(self, pretrained_word_vectors, is_static=False):\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(pretrained_word_vectors).float())\n",
    "        if is_static:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, inputs, is_training=False):\n",
    "        inputs = self.embedding(inputs).unsqueeze(1) # (B,1,T,D)\n",
    "        inputs = [F.relu(conv(inputs)).squeeze(3) for conv in self.convs] #[(N,Co,W), ...]*len(Ks)\n",
    "        inputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in inputs] #[(N,Co), ...]*len(Ks)\n",
    "\n",
    "        concated = torch.cat(inputs, 1)\n",
    "\n",
    "        if is_training:\n",
    "            concated = self.dropout(concated) # (N,len(Ks)*Co)\n",
    "        out = self.fc(concated) \n",
    "        return F.log_softmax(out,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 6\n",
    "BATCH_SIZE = 128\n",
    "KERNEL_SIZES = [3,4,5]\n",
    "KERNEL_DIM = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier(len(word2index), 300, len(target2index), KERNEL_DIM, KERNEL_SIZES)\n",
    "model.init_weights(pretrained_vectors) # initialize embedding matrix using pretrained vectors\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (embedding): Embedding(314553, 300)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, model, loss_function, epoch):\n",
    "    '''\n",
    "    Trains the model for one epoch\n",
    "    '''\n",
    "    \n",
    "    model.train()\n",
    "    avg_loss = []\n",
    "    avg_train_acc = []\n",
    "    \n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        inputs, targets = pad_to_batch(batch)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        preds = model(inputs, True)\n",
    "        \n",
    "        loss = loss_function(preds, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc = (sum(preds.max(1)[1] == targets).data.tolist() / BATCH_SIZE) * 100\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('TRAIN [Epoch : {}/{}][Batch: {}] Batch Train Loss: {}, Batch Train Accuracy: {}'.format(epoch, EPOCH, \n",
    "                                                                                                i, loss.data.tolist(),\n",
    "                                                                                                train_acc))\n",
    "    \n",
    "        avg_loss.append(loss.data.tolist())\n",
    "        avg_train_acc.append(train_acc)\n",
    "        \n",
    "    avg_loss = np.mean(avg_loss)\n",
    "    avg_train_acc = np.mean(avg_train_acc)\n",
    "\n",
    "    return avg_loss, avg_train_acc\n",
    "\n",
    "def validate(val_data, model, loss_function, epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    avg_loss = []\n",
    "    avg_test_acc = []\n",
    "    \n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, val_data)):\n",
    "        inputs, targets = pad_to_batch(batch)\n",
    "        \n",
    "        preds = model(inputs, False)\n",
    "        \n",
    "        loss = loss_function(preds, targets)\n",
    "        \n",
    "        test_acc = (sum(preds.max(1)[1] == targets).data.tolist() / BATCH_SIZE) * 100\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('VAL [Epoch : {}/{}][Batch: {}] Batch Test Loss: {}, Batch Test Accuracy: {}'.format(epoch, EPOCH, \n",
    "                                                                                                i, loss.data.tolist(),\n",
    "                                                                                                test_acc))\n",
    "    \n",
    "        avg_loss.append(loss.data.tolist())\n",
    "        avg_test_acc.append(test_acc)\n",
    "        \n",
    "    avg_loss = np.mean(avg_loss)\n",
    "    avg_test_acc = np.mean(avg_test_acc)\n",
    "\n",
    "    return avg_loss, avg_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 0/6][Batch: 0] Batch Train Loss: 1.289144515991211, Batch Train Accuracy: 33.59375\n",
      "TRAIN [Epoch : 0/6][Batch: 100] Batch Train Loss: 0.5754510760307312, Batch Train Accuracy: 80.46875\n",
      "TRAIN [Epoch : 0/6][Batch: 200] Batch Train Loss: 0.5239036083221436, Batch Train Accuracy: 82.8125\n",
      "[TRAIN] EPOCH: 0, Loss: 0.5628544961719356, Accuracy: 81.09567901234568\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 0/6][Batch: 0] Batch Test Loss: 0.5170609354972839, Batch Test Accuracy: 83.59375\n",
      "[VAL] EPOCH: 0, Loss: 0.36670158748273496, Accuracy: 86.76697530864197\n",
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 1/6][Batch: 0] Batch Train Loss: 0.4112106263637543, Batch Train Accuracy: 86.71875\n",
      "TRAIN [Epoch : 1/6][Batch: 100] Batch Train Loss: 0.3799552321434021, Batch Train Accuracy: 83.59375\n",
      "TRAIN [Epoch : 1/6][Batch: 200] Batch Train Loss: 0.24571770429611206, Batch Train Accuracy: 92.96875\n",
      "[TRAIN] EPOCH: 1, Loss: 0.35793719020645315, Accuracy: 87.72183641975309\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 1/6][Batch: 0] Batch Test Loss: 0.25714540481567383, Batch Test Accuracy: 91.40625\n",
      "[VAL] EPOCH: 1, Loss: 0.2864589759229142, Accuracy: 90.04629629629629\n",
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 2/6][Batch: 0] Batch Train Loss: 0.33248794078826904, Batch Train Accuracy: 89.0625\n",
      "TRAIN [Epoch : 2/6][Batch: 100] Batch Train Loss: 0.2739756405353546, Batch Train Accuracy: 91.40625\n",
      "TRAIN [Epoch : 2/6][Batch: 200] Batch Train Loss: 0.22073547542095184, Batch Train Accuracy: 93.75\n",
      "[TRAIN] EPOCH: 2, Loss: 0.273289557316421, Accuracy: 90.33243312757202\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 2/6][Batch: 0] Batch Test Loss: 0.2763839066028595, Batch Test Accuracy: 90.625\n",
      "[VAL] EPOCH: 2, Loss: 0.26672782758135855, Accuracy: 90.84683641975309\n",
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 3/6][Batch: 0] Batch Train Loss: 0.1873689442873001, Batch Train Accuracy: 92.96875\n",
      "TRAIN [Epoch : 3/6][Batch: 100] Batch Train Loss: 0.22395005822181702, Batch Train Accuracy: 91.40625\n",
      "TRAIN [Epoch : 3/6][Batch: 200] Batch Train Loss: 0.2224760204553604, Batch Train Accuracy: 94.53125\n",
      "[TRAIN] EPOCH: 3, Loss: 0.2102524260127986, Accuracy: 92.42862654320987\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 3/6][Batch: 0] Batch Test Loss: 0.32338887453079224, Batch Test Accuracy: 90.625\n",
      "[VAL] EPOCH: 3, Loss: 0.2757311871758214, Accuracy: 91.0011574074074\n",
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 4/6][Batch: 0] Batch Train Loss: 0.10373661667108536, Batch Train Accuracy: 96.875\n",
      "TRAIN [Epoch : 4/6][Batch: 100] Batch Train Loss: 0.16853168606758118, Batch Train Accuracy: 94.53125\n",
      "TRAIN [Epoch : 4/6][Batch: 200] Batch Train Loss: 0.1122184544801712, Batch Train Accuracy: 98.4375\n",
      "[TRAIN] EPOCH: 4, Loss: 0.15508645181180028, Accuracy: 94.21296296296296\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 4/6][Batch: 0] Batch Test Loss: 0.41069045662879944, Batch Test Accuracy: 91.40625\n",
      "[VAL] EPOCH: 4, Loss: 0.2623232500052746, Accuracy: 91.46412037037037\n",
      "<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>\n",
      "TRAIN [Epoch : 5/6][Batch: 0] Batch Train Loss: 0.03212414309382439, Batch Train Accuracy: 100.0\n",
      "TRAIN [Epoch : 5/6][Batch: 100] Batch Train Loss: 0.1384126991033554, Batch Train Accuracy: 96.09375\n",
      "TRAIN [Epoch : 5/6][Batch: 200] Batch Train Loss: 0.12739083170890808, Batch Train Accuracy: 96.875\n",
      "[TRAIN] EPOCH: 5, Loss: 0.1051284175504137, Accuracy: 96.02944958847736\n",
      "<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>\n",
      "VAL [Epoch : 5/6][Batch: 0] Batch Test Loss: 0.3289732336997986, Batch Test Accuracy: 89.0625\n",
      "[VAL] EPOCH: 5, Loss: 0.2855840845976347, Accuracy: 91.42554012345678\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print('<<<<<<<<<<<<<TRAINING>>>>>>>>>>>>')\n",
    "    epoch_train_loss, epoch_train_acc = train_model(train_data, model, loss_function, epoch)\n",
    "    print('[TRAIN] EPOCH: {}, Loss: {}, Accuracy: {}'.format(epoch, epoch_train_loss, epoch_train_acc))\n",
    "    \n",
    "    \n",
    "    print('<<<<<<<<<<<<< VALIDATING >>>>>>>>>>>>')\n",
    "    epoch_val_loss, epoch_val_acc = validate(val_data, model, loss_function, epoch)\n",
    "    print('[VAL] EPOCH: {}, Loss: {}, Accuracy: {}'.format(epoch, epoch_val_loss, epoch_val_acc))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.20603015075378\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "for test in test_data:\n",
    "    pred = model(test[0]).max(1)[1]\n",
    "    pred = pred.data.tolist()[0]\n",
    "    target = test[1].data.tolist()[0][0]\n",
    "    if pred == target:\n",
    "        accuracy += 1\n",
    "\n",
    "print(accuracy/len(test_data) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make nice plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Y_TEST' in locals():\n",
    "    del Y_TEST, Y_TEST_PREDS\n",
    "    \n",
    "for data in getBatch(50, test_data):\n",
    "    inputs, targets = pad_to_batch(data)\n",
    "\n",
    "    y_test_pred = model(inputs, False)\n",
    "    preds = y_test_pred.max(1)[1]\n",
    "    \n",
    "    if 'Y_TEST' in locals():\n",
    "        Y_TEST = torch.cat((Y_TEST, targets), 0)\n",
    "        Y_TEST_PREDS = torch.cat((Y_TEST_PREDS, preds), 0)\n",
    "    else:\n",
    "        Y_TEST = targets\n",
    "        Y_TEST_PREDS = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(Y_TEST, Y_TEST_PREDS, labels = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to plot confusion matrices, will be needed later\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar( )\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.98156625 0.01410367 0.00433008]\n",
      " [0.44862155 0.4160401  0.13533835]\n",
      " [0.1261077  0.07157464 0.80231766]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAEmCAYAAAAwZhg4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae22d03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, ['Rejected', 'Non-Core', 'Core'], normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
